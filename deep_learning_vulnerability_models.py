import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (LSTM, Dense, Dropout, Embedding, Conv1D, 
                                   GlobalMaxPooling1D, Bidirectional, Input,
                                   BatchNormalization, Concatenate, Flatten)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pickle
import os
import warnings
import time
import psutil
warnings.filterwarnings('ignore')

# Set memory growth for GPU (if available)
physical_devices = tf.config.experimental.list_physical_devices('GPU')
if len(physical_devices) > 0:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
    print("üéÆ GPU detected and configured for memory growth")
else:
    print("üíª Running on CPU")

class VulnerabilityDeepLearning:
    def __init__(self, data_path="E:/project dataset/processed_data/processed_data"):
        """
        Initialize Deep Learning models for vulnerability detection
        """
        self.data_path = data_path
        self.lstm_model = None
        self.cnn_model = None
        self.hybrid_model = None
        self.vocab_size = 0
        self.max_sequence_length = 0
        self.results = {}
        
        # Hardware optimization
        self.memory_limit = psutil.virtual_memory().available / (1024**3)
        print(f"Available RAM: {self.memory_limit:.1f}GB")
        
        # Configure TensorFlow for your hardware
        tf.config.threading.set_inter_op_parallelism_threads(2)
        tf.config.threading.set_intra_op_parallelism_threads(4)
    
    def debug_pickle_files(self):
        """Debug and inspect the pickle files to understand their structure"""
        print("üîç Debugging pickle files structure...")
        
        try:
            # Check train tokens file
            with open(os.path.join(self.data_path, 'train_tokens.pkl'), 'rb') as f:
                train_data = pickle.load(f)
            
            print(f"Train data type: {type(train_data)}")
            
            if isinstance(train_data, pd.DataFrame):
                print(f"Train DataFrame columns: {list(train_data.columns)}")
                print(f"Train DataFrame shape: {train_data.shape}")
                print(f"Train DataFrame head:")
                print(train_data.head())
            elif isinstance(train_data, dict):
                print(f"Train data keys: {list(train_data.keys())}")
                for key in train_data.keys():
                    print(f"  {key}: {type(train_data[key])}")
            else:
                print(f"Train data structure: {train_data}")
                
            return train_data
            
        except Exception as e:
            print(f"Error inspecting pickle files: {e}")
            return None
    
    def load_tokenized_data_fixed(self):
        """Load tokenized data with flexible structure handling"""
        try:
            start_time = time.time()
            print("Loading tokenized code data...")
            
            # First, debug the file structure
            sample_data = self.debug_pickle_files()
            if sample_data is None:
                return False
            
            # Load all pickle files
            with open(os.path.join(self.data_path, 'train_tokens.pkl'), 'rb') as f:
                train_data = pickle.load(f)
            with open(os.path.join(self.data_path, 'val_tokens.pkl'), 'rb') as f:
                val_data = pickle.load(f)
            with open(os.path.join(self.data_path, 'test_tokens.pkl'), 'rb') as f:
                test_data = pickle.load(f)
            
            # Handle different data structures
            def extract_tokens_and_labels(data):
                if isinstance(data, pd.DataFrame):
                    # Check available columns
                    print(f"Available columns: {list(data.columns)}")
                    
                    # Try different possible column names for tokens
                    token_col = None
                    for col_name in ['code_tokens', 'tokens', 'sequences', 'text']:
                        if col_name in data.columns:
                            token_col = col_name
                            break
                    
                    # Try different possible column names for labels
                    label_col = None
                    for col_name in ['vul', 'vulnerable', 'label', 'target']:
                        if col_name in data.columns:
                            label_col = col_name
                            break
                    
                    if token_col and label_col:
                        tokens = data[token_col].tolist()
                        labels = data[label_col].values
                        print(f"Using columns: {token_col} (tokens), {label_col} (labels)")
                        return tokens, labels
                    else:
                        print(f"‚ö†Ô∏è Could not find token/label columns. Available: {list(data.columns)}")
                        # Try using index-based access if only 2 columns
                        if len(data.columns) == 2:
                            tokens = data.iloc[:, 0].tolist()
                            labels = data.iloc[:, 1].values
                            print(f"Using first column as tokens, second as labels")
                            return tokens, labels
                        else:
                            return None, None
                
                elif isinstance(data, dict):
                    # Handle dictionary structure
                    if 'code_tokens' in data and 'vul' in data:
                        return data['code_tokens'], data['vul']
                    else:
                        print(f"Dictionary keys: {list(data.keys())}")
                        return None, None
                else:
                    print(f"Unsupported data type: {type(data)}")
                    return None, None
            
            # Extract data from all splits
            self.X_train_tokens, self.y_train = extract_tokens_and_labels(train_data)
            self.X_val_tokens, self.y_val = extract_tokens_and_labels(val_data)
            self.X_test_tokens, self.y_test = extract_tokens_and_labels(test_data)
            
            # Check if extraction was successful
            if any(x is None for x in [self.X_train_tokens, self.y_train, self.X_val_tokens, 
                                     self.y_val, self.X_test_tokens, self.y_test]):
                print("‚ùå Failed to extract tokens and labels from pickle files")
                return False
            
            load_time = time.time() - start_time
            print(f"‚úÖ Tokenized data loaded successfully in {load_time:.2f} seconds")
            
            print(f"Train sequences: {len(self.X_train_tokens)}")
            print(f"Validation sequences: {len(self.X_val_tokens)}")
            print(f"Test sequences: {len(self.X_test_tokens)}")
            
            # Inspect a few samples
            print(f"\nSample token sequence (first 10 tokens): {self.X_train_tokens[0][:10]}")
            print(f"Sample label: {self.y_train[0]}")
            
            # Analyze sequence lengths
            all_lengths = [len(seq) for seq in self.X_train_tokens + self.X_val_tokens + self.X_test_tokens]
            self.max_sequence_length = min(int(np.percentile(all_lengths, 95)), 500)  # Cap at 500
            
            print(f"\nSequence length statistics:")
            print(f"  Min: {np.min(all_lengths)}")
            print(f"  Max: {np.max(all_lengths)}")  
            print(f"  Mean: {np.mean(all_lengths):.1f}")
            print(f"  95th percentile: {np.percentile(all_lengths, 95):.1f}")
            print(f"  Using max length: {self.max_sequence_length}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading tokenized data: {e}")
            print("üîß Let's try alternative approach...")
            return self.load_from_csv_alternative()
    
    def load_from_csv_alternative(self):
        """Alternative: Load from CSV files and create tokens from code"""
        try:
            print("üîß Trying alternative approach: Loading from CSV and tokenizing...")
            
            # Load CSV files
            train_df = pd.read_csv(os.path.join(self.data_path, 'train_features.csv'))
            val_df = pd.read_csv(os.path.join(self.data_path, 'val_features.csv'))
            test_df = pd.read_csv(os.path.join(self.data_path, 'test_features.csv'))
            
            print(f"CSV files loaded successfully")
            print(f"Available columns: {list(train_df.columns)}")
            
            # Create simple token sequences from available features
            # This is a fallback approach using numerical features as a sequence
            feature_cols = [col for col in train_df.columns if col != 'vul']
            
            def create_token_sequence(row):
                # Convert numerical features to token-like representation
                tokens = []
                for col in feature_cols:
                    value = row[col]
                    if pd.isna(value):
                        tokens.append('NULL')
                    elif isinstance(value, (int, float)):
                        # Discretize numerical values
                        if value == 0:
                            tokens.append(f'{col}_ZERO')
                        elif value < 10:
                            tokens.append(f'{col}_SMALL')
                        elif value < 100:
                            tokens.append(f'{col}_MEDIUM')
                        else:
                            tokens.append(f'{col}_LARGE')
                    else:
                        tokens.append(f'{col}_{str(value)}')
                return tokens
            
            # Create token sequences
            self.X_train_tokens = [create_token_sequence(row) for _, row in train_df.iterrows()]
            self.X_val_tokens = [create_token_sequence(row) for _, row in val_df.iterrows()]
            self.X_test_tokens = [create_token_sequence(row) for _, row in test_df.iterrows()]
            
            # Extract labels
            self.y_train = train_df['vul'].values
            self.y_val = val_df['vul'].values
            self.y_test = test_df['vul'].values
            
            # Set max sequence length
            all_lengths = [len(seq) for seq in self.X_train_tokens + self.X_val_tokens + self.X_test_tokens]
            self.max_sequence_length = max(all_lengths)
            
            print(f"‚úÖ Alternative tokenization successful!")
            print(f"Created sequences from {len(feature_cols)} features")
            print(f"Sample sequence: {self.X_train_tokens[0]}")
            print(f"Max sequence length: {self.max_sequence_length}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Alternative approach also failed: {e}")
            return False
    
    def prepare_sequences(self):
        """Convert tokens to integer sequences and pad them"""
        print("\nüîß Preparing sequences for deep learning...")
        
        # Flatten all tokens to create vocabulary
        all_tokens = []
        for seq_list in [self.X_train_tokens, self.X_val_tokens, self.X_test_tokens]:
            for seq in seq_list:
                all_tokens.extend(seq)
        
        # Create vocabulary mapping
        unique_tokens = list(set(all_tokens))
        self.vocab_size = len(unique_tokens) + 2  # +2 for PAD and UNK
        
        # Create token to integer mapping
        token_to_int = {token: i+2 for i, token in enumerate(unique_tokens)}
        token_to_int['<PAD>'] = 0
        token_to_int['<UNK>'] = 1
        
        print(f"Vocabulary size: {self.vocab_size}")
        print(f"Max sequence length: {self.max_sequence_length}")
        
        # Convert tokens to integers
        def tokens_to_sequences(token_lists):
            sequences = []
            for tokens in token_lists:
                seq = [token_to_int.get(token, 1) for token in tokens]
                sequences.append(seq)
            return sequences
        
        # Convert all datasets
        X_train_seq = tokens_to_sequences(self.X_train_tokens)
        X_val_seq = tokens_to_sequences(self.X_val_tokens)
        X_test_seq = tokens_to_sequences(self.X_test_tokens)
        
        # Pad sequences
        self.X_train_padded = pad_sequences(X_train_seq, maxlen=self.max_sequence_length, padding='post', truncating='post')
        self.X_val_padded = pad_sequences(X_val_seq, maxlen=self.max_sequence_length, padding='post', truncating='post')
        self.X_test_padded = pad_sequences(X_test_seq, maxlen=self.max_sequence_length, padding='post', truncating='post')
        
        print(f"‚úÖ Sequences prepared! Shape: {self.X_train_padded.shape}")
    
    def build_lstm_model(self, embedding_dim=64, lstm_units=32):
        """Build LSTM model optimized for your hardware"""
        print(f"\nüèóÔ∏è Building LSTM model...")
        
        model = Sequential([
            Embedding(input_dim=self.vocab_size, 
                     output_dim=embedding_dim, 
                     input_length=self.max_sequence_length,
                     mask_zero=True),
            
            Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)),
            Bidirectional(LSTM(lstm_units//2, dropout=0.3, recurrent_dropout=0.2)),
            
            Dense(32, activation='relu'),
            Dropout(0.5),
            BatchNormalization(),
            
            Dense(16, activation='relu'),
            Dropout(0.3),
            
            Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        print("‚úÖ LSTM Model built successfully!")
        model.summary()
        return model
    
    def build_cnn_model(self, embedding_dim=64, num_filters=32):
        """Build CNN model optimized for your hardware"""
        print(f"\nüèóÔ∏è Building CNN model...")
        
        model = Sequential([
            Embedding(input_dim=self.vocab_size, 
                     output_dim=embedding_dim, 
                     input_length=self.max_sequence_length),
            
            Conv1D(filters=num_filters, kernel_size=3, activation='relu', padding='same'),
            Conv1D(filters=num_filters, kernel_size=4, activation='relu', padding='same'),
            Conv1D(filters=num_filters, kernel_size=5, activation='relu', padding='same'),
            
            BatchNormalization(),
            Dropout(0.3),
            
            GlobalMaxPooling1D(),
            
            Dense(64, activation='relu'),
            Dropout(0.5),
            BatchNormalization(),
            
            Dense(32, activation='relu'),
            Dropout(0.3),
            
            Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        print("‚úÖ CNN Model built successfully!")
        model.summary()
        return model
    
    def train_model(self, model, model_name, epochs=20, batch_size=32):
        """Train model with callbacks"""
        print(f"\nüöÄ Training {model_name} model...")
        
        # Class weights for imbalanced data
        class_weight = {
            0: 1.0,
            1: len(self.y_train) / (2 * np.sum(self.y_train))
        }
        print(f"Class weights: {class_weight}")
        
        # Callbacks
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),
            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1)
        ]
        
        start_time = time.time()
        
        history = model.fit(
            self.X_train_padded, self.y_train,
            validation_data=(self.X_val_padded, self.y_val),
            epochs=epochs,
            batch_size=batch_size,
            class_weight=class_weight,
            callbacks=callbacks,
            verbose=1
        )
        
        training_time = time.time() - start_time
        print(f"‚úÖ {model_name} training completed in {training_time/60:.1f} minutes")
        
        return history
    
    def evaluate_model(self, model, model_name):
        """Evaluate trained model"""
        print(f"\nüìä Evaluating {model_name} model...")
        
        # Predictions
        train_pred_proba = model.predict(self.X_train_padded, verbose=0).flatten()
        val_pred_proba = model.predict(self.X_val_padded, verbose=0).flatten()
        test_pred_proba = model.predict(self.X_test_padded, verbose=0).flatten()
        
        # Binary predictions
        train_pred = (train_pred_proba > 0.5).astype(int)
        val_pred = (val_pred_proba > 0.5).astype(int)
        test_pred = (test_pred_proba > 0.5).astype(int)
        
        # Calculate metrics
        datasets = {
            'Train': (self.y_train, train_pred, train_pred_proba),
            'Validation': (self.y_val, val_pred, val_pred_proba),
            'Test': (self.y_test, test_pred, test_pred_proba)
        }
        
        model_results = {}
        
        for split_name, (y_true, y_pred, y_proba) in datasets.items():
            metrics = {
                'accuracy': accuracy_score(y_true, y_pred),
                'precision': precision_score(y_true, y_pred, zero_division=0),
                'recall': recall_score(y_true, y_pred, zero_division=0),
                'f1': f1_score(y_true, y_pred, zero_division=0),
                'auc_roc': roc_auc_score(y_true, y_proba)
            }
            
            model_results[split_name] = metrics
            
            print(f"\n{split_name} Set Performance:")
            for metric_name, value in metrics.items():
                print(f"  {metric_name.capitalize()}: {value:.4f}")
        
        self.results[model_name] = model_results
        
        print(f"\nDetailed Test Set Classification Report:")
        print(classification_report(self.y_test, test_pred))
        
        return model_results
    
    def plot_results(self, history, model_name):
        """Plot training history"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        # Accuracy
        axes[0, 0].plot(history.history['accuracy'], label='Training')
        axes[0, 0].plot(history.history['val_accuracy'], label='Validation')
        axes[0, 0].set_title(f'{model_name} - Accuracy')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # Loss
        axes[0, 1].plot(history.history['loss'], label='Training')
        axes[0, 1].plot(history.history['val_loss'], label='Validation')
        axes[0, 1].set_title(f'{model_name} - Loss')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # Precision
        axes[1, 0].plot(history.history['precision'], label='Training')
        axes[1, 0].plot(history.history['val_precision'], label='Validation')
        axes[1, 0].set_title(f'{model_name} - Precision')
        axes[1, 0].set_ylabel('Precision')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        # Recall
        axes[1, 1].plot(history.history['recall'], label='Training')
        axes[1, 1].plot(history.history['val_recall'], label='Validation')
        axes[1, 1].set_title(f'{model_name} - Recall')
        axes[1, 1].set_ylabel('Recall')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].legend()
        axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.savefig(f'./results/{model_name}_training_history.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    def run_complete_pipeline(self):
        """Run the complete pipeline with error handling"""
        total_start_time = time.time()
        
        print("="*70)
        print("VULNERABILITY DETECTION - DEEP LEARNING PIPELINE (FIXED)")
        print("="*70)
        
        # Create directories
        os.makedirs('./models', exist_ok=True)
        os.makedirs('./results', exist_ok=True)
        
        # Step 1: Load data
        if not self.load_tokenized_data_fixed():
            print("‚ùå Failed to load tokenized data")
            return False
        
        # Step 2: Prepare sequences
        self.prepare_sequences()
        
        # Step 3: Train LSTM
        print("\n" + "="*50)
        print("TRAINING LSTM MODEL")
        print("="*50)
        try:
            self.lstm_model = self.build_lstm_model()
            lstm_history = self.train_model(self.lstm_model, "LSTM", epochs=15, batch_size=32)
            self.evaluate_model(self.lstm_model, "LSTM")
            self.plot_results(lstm_history, "LSTM")
            
            # Save model
            self.lstm_model.save('./models/lstm_vulnerability_model.h5')
            print("‚úÖ LSTM model saved successfully!")
            
        except Exception as e:
            print(f"‚ùå LSTM training failed: {e}")
        
        # Step 4: Train CNN
        print("\n" + "="*50)
        print("TRAINING CNN MODEL")
        print("="*50)
        try:
            self.cnn_model = self.build_cnn_model()
            cnn_history = self.train_model(self.cnn_model, "CNN", epochs=15, batch_size=32)
            self.evaluate_model(self.cnn_model, "CNN")
            self.plot_results(cnn_history, "CNN")
            
            # Save model
            self.cnn_model.save('./models/cnn_vulnerability_model.h5')
            print("‚úÖ CNN model saved successfully!")
            
        except Exception as e:
            print(f"‚ùå CNN training failed: {e}")
        
        # Step 5: Compare results
        if self.results:
            print("\n" + "="*50)
            print("MODEL COMPARISON")
            print("="*50)
            
            for model_name, model_results in self.results.items():
                print(f"\n{model_name} Test Results:")
                test_metrics = model_results['Test']
                for metric, value in test_metrics.items():
                    print(f"  {metric.capitalize()}: {value:.4f}")
            
            # Save results
            results_df = pd.DataFrame({
                model: results['Test'] 
                for model, results in self.results.items()
            }).T
            results_df.to_csv('./results/deep_learning_results.csv')
            print("\n‚úÖ Results saved to './results/deep_learning_results.csv'")
        
        total_time = time.time() - total_start_time
        print(f"\n" + "="*70)
        print(f"PIPELINE COMPLETED IN {total_time/60:.1f} MINUTES!")
        print("="*70)
        
        return True

# Usage
if __name__ == "__main__":
    dl_model = VulnerabilityDeepLearning(data_path="E:/project dataset/processed_data/processed_data")
    
    success = dl_model.run_complete_pipeline()
    
    if success:
        print("\n‚úÖ Deep learning pipeline completed successfully!")
    else:
        print("‚ùå Pipeline failed. Check the error messages above.")